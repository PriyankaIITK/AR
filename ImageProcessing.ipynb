{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAr7DNvaUYbJf2GB9Rc/Uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaIITK/AR/blob/main/ImageProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kpIAFTyPhCm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import tensorflow as tf\n",
        "except:\n",
        "  !pip install tensorflow\n",
        "  import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "t4EMmc4oPsX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv_to_dataset(csv_path, img_dir, target_size=(128, 128), batch_size=32, shuffle=True, label_map=None):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Create label map\n",
        "    if label_map is None:\n",
        "      labels = sorted(df['class'].unique())\n",
        "      label_map = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "    filepaths = df['filename'].apply(lambda x: os.path.join(img_dir, x)).values\n",
        "    labels = df['class'].apply(lambda x: label_map[x]).values\n",
        "\n",
        "    # Create TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
        "\n",
        "    def process_image(file_path, label):\n",
        "        img = tf.io.read_file(file_path)\n",
        "        img = tf.image.decode_jpeg(img, channels=3)\n",
        "        img = tf.image.resize(img, target_size)\n",
        "        img = tf.cast(img, tf.float32) / 255.0\n",
        "        label = tf.one_hot(label, depth=len(label_map))\n",
        "        return img, label\n",
        "\n",
        "    dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset, label_map"
      ],
      "metadata": {
        "id": "WvGKyoEPPxxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eFb25_KvP28B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, label_map = load_csv_to_dataset(\n",
        "    '/content/drive/MyDrive/Dataset/train/_annotations.csv',\n",
        "    '/content/drive/MyDrive/Dataset/train',\n",
        "    shuffle=True)\n",
        "\n",
        "val_ds, _ = load_csv_to_dataset(\n",
        "    '/content/drive/MyDrive/Dataset/valid/_annotations.csv',\n",
        "    '/content/drive/MyDrive/Dataset/valid',\n",
        "    shuffle=False, label_map = label_map)\n",
        "\n",
        "test_ds, _ = load_csv_to_dataset(\n",
        "    '/content/drive/MyDrive/Dataset/test/_annotations.csv',\n",
        "    '/content/drive/MyDrive/Dataset/test',\n",
        "    shuffle=False, label_map = label_map)"
      ],
      "metadata": {
        "id": "DLiXaQoqP51n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(128, 128, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_map), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "2BrsKUmiP9WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/train/_annotations.csv')\n",
        "labels = df['class'].apply(lambda x: label_map[x]).values\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "2GbSH_HGQCq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=10, class_weight=class_weights)"
      ],
      "metadata": {
        "id": "-UUl8I5cQLjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "etfZ9q4jQMjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get predictions and ground truth labels\n",
        "def get_predictions(model, test_ds):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        # Get the ground truth labels\n",
        "        y_true.extend(np.argmax(labels, axis=1))  # Convert one-hot to class index\n",
        "\n",
        "        # Get the predicted labels\n",
        "        y_pred.extend(np.argmax(model.predict(images), axis=1))\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred)\n",
        "\n",
        "# Get true labels and predicted labels\n",
        "y_true, y_pred = get_predictions(model, test_ds)\n",
        "\n",
        "# 1. Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 2. Precision\n",
        "precision = precision_score(y_true, y_pred, average='weighted')  # 'weighted' to handle imbalanced classes\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "# 3. Recall\n",
        "recall = recall_score(y_true, y_pred, average='weighted')  # 'weighted' to handle imbalanced classes\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# 4. F1-Score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')  # 'weighted' to handle imbalanced classes\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 5. Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q6ZbMiRtQQHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part b starts\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def process_single_image(img):\n",
        "    if img.shape[-1] == 1:\n",
        "        img = np.repeat(img, 3, axis=-1)\n",
        "    img_uint8 = (img * 255).astype(np.uint8)\n",
        "    if img_uint8.shape[-1] == 1:\n",
        "        img_uint8 = np.repeat(img_uint8, 3, axis=-1)\n",
        "    gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "    _, mask = cv2.threshold(closed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "def segment_defect(img):\n",
        "    img = img.numpy()\n",
        "    if img.ndim == 4:\n",
        "        results = []\n",
        "        for i in range(img.shape[0]):\n",
        "            results.append(process_single_image(img[i]))\n",
        "        return np.stack(results, axis=0)\n",
        "    else:\n",
        "        return process_single_image(img)\n",
        "\n",
        "def preprocess_image_tf(image, label):\n",
        "    mask = tf.py_function(\n",
        "        func=segment_defect,\n",
        "        inp=[image],\n",
        "        Tout=tf.uint8\n",
        "    )\n",
        "    mask.set_shape([128,128])\n",
        "    mask = tf.cast(mask, tf.float32) / 255.0\n",
        "    mask = tf.expand_dims(mask, -1)\n",
        "    mask = tf.repeat(mask, 3, axis=-1)\n",
        "    masked_image = image * mask\n",
        "    return masked_image, label\n",
        "\n",
        "# Unbatch -> map -> batch\n",
        "seg_train_ds = train_ds.unbatch().map(preprocess_image_tf, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "seg_val_ds = val_ds.unbatch().map(preprocess_image_tf, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "seg_test_ds = test_ds.unbatch().map(preprocess_image_tf, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "rWCl17wkQUdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_model = Sequential([\n",
        "    Input(shape=(128, 128, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_map), activation='softmax')\n",
        "])\n",
        "seg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "seg_history = seg_model.fit(seg_train_ds, validation_data=seg_val_ds, epochs=10, class_weight=class_weights)\n"
      ],
      "metadata": {
        "id": "BRIygeaYQakp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_test_loss, seg_test_acc = seg_model.evaluate(seg_test_ds)\n",
        "print(f\"Segmentation-based Test accuracy: {seg_test_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "DiVmjJQYQeze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, dataset):\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in dataset:\n",
        "        y_true.extend(np.argmax(labels, axis=1))\n",
        "        y_pred.extend(np.argmax(model.predict(images), axis=1))\n",
        "    return np.array(y_true), np.array(y_pred)\n",
        "\n",
        "y_true_seg, y_pred_seg = get_predictions(seg_model, seg_test_ds)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true_seg, y_pred_seg))\n",
        "print(\"Precision:\", precision_score(y_true_seg, y_pred_seg, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_true_seg, y_pred_seg, average='weighted'))\n",
        "print(\"F1-Score:\", f1_score(y_true_seg, y_pred_seg, average='weighted'))\n",
        "\n",
        "cm = confusion_matrix(y_true_seg, y_pred_seg)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
        "plt.title(\"Segmentation Model Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LWtwMAb_QjF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_segmentation_examples(dataset, n=3):\n",
        "    for images, labels in dataset.take(1):\n",
        "        plt.figure(figsize=(12,4))\n",
        "        for i in range(n):\n",
        "            plt.subplot(2, n, i+1)\n",
        "            plt.imshow(images[i].numpy())\n",
        "            plt.title(\"Segmented\")\n",
        "            plt.axis('off')\n",
        "        for i in range(n):\n",
        "            plt.subplot(2, n, n+i+1)\n",
        "            # Get original image from test_ds (without segmentation)\n",
        "            for orig_images, _ in test_ds.take(1):\n",
        "                plt.imshow(orig_images[i].numpy())\n",
        "                plt.title(\"Original\")\n",
        "                plt.axis('off')\n",
        "        plt.show()\n",
        "show_segmentation_examples(seg_test_ds, n=4)"
      ],
      "metadata": {
        "id": "bqese1A6QnyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Baseline Test accuracy:\", test_acc)\n",
        "print(\"Segmentation-based Test accuracy:\", seg_test_acc)\n"
      ],
      "metadata": {
        "id": "imDFTYw4QsQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}